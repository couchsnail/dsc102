{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285a4873-ff33-4ff1-b7d2-0032254484fe",
   "metadata": {},
   "source": [
    "## <font color='red'> INSTRUCTIONS </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89957ed8-c2d1-4592-8821-88806390d1cc",
   "metadata": {},
   "source": [
    "<b> \n",
    "1. Write your code only in cells below the \"WRITE CODE BELOW\" title. Do not modify the code below the \"DO NOT MODIFY\" title. <br>\n",
    "2. The expected data types of the output answers for each question are given in the last cell through assertion statements. Your answers must match these expected output data types. Hint: Many of the answers need to be a Python dictionary. Consider methods like to_dict() to convert a Pandas Series to a dictionary. <br>\n",
    "3. The answers are then written to a JSON file named my_results_PA1.json. You can compare this with the provided expected output file \"expected_results_PA1.json\". <br>\n",
    "4. After you complete writing your code, click \"Kernel -> Restart Kernel and Run All Cells\" on the top toolbar. There should NOT be any syntax/runtime errors, otherwise points will be deducted. <br>\n",
    "5. For submitting your solution, first download your notebook by clicking \"File -> Download\". Rename the file as &ltTEAM_ID&gt.ipynb\" and upload to Canvas.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f7e94-c5b1-494c-8aab-832242527a4e",
   "metadata": {},
   "source": [
    "## <font color='red'> DO NOT MODIFY </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76f3c8d7-690f-428b-982d-94265b4a7f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/dask_env/lib/python3.10/site-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 40937 instead\n",
      "  warnings.warn(\n",
      "2025-05-09 09:46:45,880 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-05-09 09:46:45,887 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-05-09 09:46:45,891 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-05-09 09:46:45,896 - distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 09:51:07,006 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:45761' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 271), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 36), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 289), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 228), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 54), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 292), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 231), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 2), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 246), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 69), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 8), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 72), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 87), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 206), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 264), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 32), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 279), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 224), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 282), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 47), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 285), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 50), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 239), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 4), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 242), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 306), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 65), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 196), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 260), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 25), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 257), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 83), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 202), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 31), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 217), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 275), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 220), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 98), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 43), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 296), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 235), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 61), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 58), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 3), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 9), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 302), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 314), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 253), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 76), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 21), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 268), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 94), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 213)} (stimulus_id='handle-worker-cleanup-1746784267.0061393')\n",
      "2025-05-09 09:51:07,028 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:40851' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 225), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 51), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 283), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 48), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 298), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 243), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 66), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 304), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 258), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 197), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 203), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 261), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 20), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 84), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 90), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 99), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 218), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 44), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 276), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 221), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 236), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 294), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 300), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 59), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 62), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 7), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 315), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 254), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 80), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 77), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 269), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 28), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 272), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 37), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 95), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 214), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 40), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 229), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 287), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 232), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 290), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 55), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 250), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 308), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 247), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 73), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 311), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 265), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 24), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 210), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 88), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 207), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 33)} (stimulus_id='handle-worker-cleanup-1746784267.028348')\n",
      "2025-05-09 09:51:07,033 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:34249' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 277), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 222), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 280), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 219), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 45), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 295), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 237), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 63), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 301), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 240), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 255), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 78), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 316), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 23), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 81), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 200), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 96), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 215), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 273), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 38), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 41), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 288), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 291), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 56), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 233), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 248), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 312), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 251), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 309), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 74), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 89), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 208), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 266), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 92), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 211), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 34), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 284), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 49), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 226), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 52), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 6), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 305), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 299), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 70), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 244), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 67), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 198), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 262), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 259), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 85), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 204), ('read-_to_string_dtype-lambda-07ae5c08706f590f8fa7c977f48b1694', 27)} (stimulus_id='handle-worker-cleanup-1746784267.0328739')\n",
      "2025-05-09 09:51:09,243 - distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from dask.distributed import Client\n",
    "import ctypes\n",
    "import numpy as np\n",
    "\n",
    "def trim_memory() -> int:\n",
    "    \"\"\"\n",
    "    helps to fix any memory leaks.\n",
    "    \"\"\"\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    return libc.malloc_trim(0)\n",
    "\n",
    "# change client url to the dask worker url from one of our 5 billion terminals ig\n",
    "client = Client(\"172.31.35.90:8786\")\n",
    "client.run(trim_memory)\n",
    "client = client.restart()\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb6ac532-d64f-4659-9cc8-94481f48c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b6eb9-e5d7-423a-a0bc-7b86e6db1ab4",
   "metadata": {},
   "source": [
    "## <font color='blue'> WRITE CODE BELOW </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15d65e9-090c-49be-b4a1-7c193ed27fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews = dd.read_csv('user_reviews.csv')\n",
    "products = dd.read_csv('products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68351495-2c7f-4a49-af75-5fd4a9b7d32c",
   "metadata": {},
   "source": [
    "# Hints\n",
    "\n",
    "1. We advise you to start using 5 instances so that you can test your code faster. This aligns with the “fail-fast”\n",
    "philosophy. Once your code is working you can measure the runtime on two and five instances and make\n",
    "further optimizations.\n",
    "2. What are dangling references?\n",
    "If there is a value V in column X of table A, but this value is missing in column X of table B, we say that\n",
    "V is a dangling reference of X from A to B.\n",
    "For example, consider the below two tables:\n",
    "ID X\n",
    "1 21\n",
    "2 32\n",
    "3 1\n",
    "ID Y\n",
    "1 4\n",
    "3 5\n",
    "Here, ID 2 is a dangling reference from the first table to the second.\n",
    "3. Worker logs will be output to the terminals where you started your workers and may not appear in jupyter-\n",
    "notebook. You will need to check the terminal output for your workers to debug any errors.\n",
    "2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bd542b-4635-4477-8ded-5f9c8a57684a",
   "metadata": {},
   "source": [
    "# Q1: Get percentage of missing values for all columns in the reviews table.\n",
    "## Output must be a dictionary with col names as keys and percentages as values\n",
    "Idea: iterate through each column, calling count na and then dividing by dataframe shape?\n",
    "- Not sure how this works with partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62988c40-b69d-4d3c-b2b8-0421db5252ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID           0\n",
       "asin                 0\n",
       "reviewerName      3726\n",
       "helpful              0\n",
       "reviewText          20\n",
       "overall              0\n",
       "summary             13\n",
       "unixReviewTime       0\n",
       "reviewTime           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_reviews.map_partitions(lambda x: x.isna().sum()).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a4a619-49bf-48b9-be1d-da0d3e50385f",
   "metadata": {},
   "source": [
    "# Q2. Get percentage of missing values for all columns in the products table.\n",
    "## For output type see Q1\n",
    "Idea: iterate through each column, calling count na and then dividing by dataframe shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b33ac2-045c-43c5-a12e-cc537dd203b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "products.map_partitions(lambda x: x.isna().sum()).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3311185-b201-42be-83c6-2aed2c507925",
   "metadata": {},
   "source": [
    "# Q3. Find Pearson correlation coefficient between the price and rating of the products.\n",
    "## Output must be a float\n",
    "Idea: grab price column from the product table and the rating column from the review table then calculate Pearson\n",
    "- Pearson correlation formula: sum(x_i - x_bar)(y_i - y_bar)/square root(sum(x_i-x_bar)^2 * sum(y_i - y_bar)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccdda67-d362-4ce7-a38c-3359a2205656",
   "metadata": {},
   "source": [
    "# Q4. Find mean, standard deviation, median, min, and max for the price column in the products table.\n",
    "## Output must be a dictionary\n",
    "Idea: \n",
    "- Grab the price column from the products table\n",
    "- Calculate each of the metrics by calling pandas on the partitions???\n",
    "- Not sure the exact format but we'll find out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b3c87c-2342-42e6-ae55-c1347c9add08",
   "metadata": {},
   "source": [
    "# Q5. Find number of products for each super-category (the first entry in the “categories” column in the products table). Output categories should be sorted in non-increasing order in the number of products. Categories with the same number of products can appear in any order.\n",
    "## Output should be a dictionary\n",
    "Idea: \n",
    "- Process the category column from the products table and get first value from each list\n",
    "- Groupby this processed column and use .count()\n",
    "- Sort in non-increasing order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ba762-c661-4745-971e-04db291356f8",
   "metadata": {},
   "source": [
    "# Q6. Check (return 1 or 0) if there are any dangling references from product ids in the reviews table to products table. Return 1 if there are dangling references and 0 otherwise.\n",
    "## Output should be a Boolean\n",
    "Idea:\n",
    "- Join??? might be super inefficient\n",
    "- Get the number of unique product ids in reviews and see if == number of unique product ids in products\n",
    "- This is the asin column btw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f574f62-4efd-42f4-9657-10c4d35ceaef",
   "metadata": {},
   "source": [
    "# Q7. Check (return 1 or 0) if there are any dangling references from product ids in the “related” column to the “asin” column of the product table. Return 1 if there are dangling references and 0 otherwise.\n",
    "## Output should be a Boolean\n",
    "Idea: \n",
    "- So I think this question is asking if there are asins that are not in any of the related columns\n",
    "- Process the related column in the product table, which is currently a dictionary where keys are 'Also viewed', 'Bought after', etc. and entries are lists of asins\n",
    "- Going to have to use a lambda function on the dict\n",
    "- Kinda iffy idea: iterate through the related column, adding unique ids to a list and seeing if the length of .unique() of that == length of .unique() on asins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf416f4d-1782-4fa5-9b2b-b44aafd55934",
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in the 'user_reviews.csv' and 'products.csv' files, perform your calculations and place the answers in variables ans1 - ans7.\n",
    "\n",
    "\n",
    "# substitute 'None' with the outputs from your calculations. \n",
    "# The expected output types can be seen in the assertion statements below\n",
    "ans1 = None\n",
    "ans2 = None\n",
    "ans3 = None\n",
    "ans4 = None\n",
    "ans5 = None\n",
    "ans6 = None\n",
    "ans7 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d92954-28b3-4ad0-b7de-d8b8f4816c80",
   "metadata": {},
   "source": [
    "## <font color='red'> DO NOT MODIFY </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438177d-8c4d-4871-bbc6-bea2f0a004b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adca53b-b276-4297-8434-6c0e94810d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"execution time = {end-start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935be195-dcc9-4e97-911a-bae25e2a70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "assert type(ans1) == dict, f\"answer to question 1 must be a dictionary like {{'reviewerID':0.2, ..}}, got type = {type(ans1)}\"\n",
    "assert type(ans2) == dict, f\"answer to question 2 must be a dictionary like {{'asin':0.2, ..}}, got type = {type(ans2)}\"\n",
    "assert type(ans3) == float, f\"answer to question 3 must be a float like 0.8, got type = {type(ans3)}\"\n",
    "assert type(ans4) == dict, f\"answer to question 4 must be a dictionary like {{'mean':0.4,'max':0.6,'median':0.6...}}, got type = {type(ans4)}\"\n",
    "assert type(ans5) == dict, f\"answer to question 5 must be a dictionary, got type = {type(ans5)}\"         \n",
    "assert ans6 == 0 or ans6==1, f\"answer to question 6 must be 0 or 1, got value = {ans6}\" \n",
    "assert ans7 == 0 or ans7==1, f\"answer to question 7 must be 0 or 1, got value = {ans7}\" \n",
    "\n",
    "ans_dict = {\n",
    "    \"q1\": ans1,\n",
    "    \"q2\": ans2,\n",
    "    \"q3\": ans3,\n",
    "    \"q4\": ans4,\n",
    "    \"q5\": ans5,\n",
    "    \"q6\": ans6,\n",
    "    \"q7\": ans7,\n",
    "    \"runtime\": end-start\n",
    "}\n",
    "with open('my_results_PA1.json', 'w') as outfile: json.dump(ans_dict, outfile)         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
